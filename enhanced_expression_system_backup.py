# Enhanced Expression System - LLM-Conditioned Response Generation
# Replaces template-based responses with persona-conditioned LLM generation

import json
import os
import time
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import random

from llm_fine_tuning_system import LLMFineTuningSystem
from humanness_reward_model import HumannessRewardModel, HumannessFeatures
from strategy_composer import StrategyComposer, PsychologicalDirective
from unified_cns_personality import PsychologyToPersonaTranslator, PersonaState, JamesBondPersona

@dataclass
class ExpressionContext:
    """Enhanced context for strategic expression generation"""
    user_input: str
    emotional_state: Dict[str, Any]
    persona: str
    conversation_history: List[Dict[str, str]]
    relationship_level: str
    user_preferences: Dict[str, Any]
    current_mood: str
    recent_topics: List[str]
    # NEW: Strategic intelligence from psychopath module
    strategic_analysis: Optional[Dict[str, Any]] = None
    vulnerability_assessment: Optional[Dict[str, Any]] = None
    manipulation_framework: Optional[Dict[str, Any]] = None
    cns_emotional_intelligence_full: Optional[Dict[str, Any]] = None
    accumulated_intelligence_summary: Optional[str] = None
    # NEW: Curiosity & gap detection for natural follow-up questions
    curiosity_signals: Optional[Dict[str, Any]] = None
    # NEW: Strategic response directive - EXACT decision from psychopath brain
    strategic_directive: Optional[Dict[str, Any]] = None  # EXACT approach/manipulation technique - CONTROLS LLM output
    # NEW: Complete cognitive flow - ALL upstream systems
    perception_data: Optional[Dict[str, Any]] = None  # Intent, sentiment, entities, urgency
    reasoning_output: Optional[Dict[str, Any]] = None  # System 1/2 decision, conclusions, thoughts
    orchestration_state: Optional[Dict[str, Any]] = None  # Priority, cognitive_load
    memory_results: Optional[Dict[str, Any]] = None  # Episodic, semantic, working memories
    imagination_insights: Optional[Dict[str, Any]] = None  # Counterfactuals, creative energy
    consciousness_metrics: Optional[Dict[str, Any]] = None  # Self-awareness, metacognition
    neuroplastic_state: Optional[Dict[str, Any]] = None  # Optimization efficiency
    contribution_context: Optional[Dict[str, Any]] = None  # Bot's knowledge/opinions/memories to contribute (contribution-first responses)
    emotional_history: Optional[List[Dict[str, Any]]] = None  # Emotional trajectory - evolution of emotions across conversation
    interaction_count: Optional[int] = None  # Number of conversations with this user
    # NEW: REM subconscious insights - pattern discoveries from background processing
    rem_insights: Optional[Dict[str, Any]] = None  # Discovered patterns, themes, connections from REM cycles
    # NEW: Proactive helper status - active tasks, solutions, research in progress
    proactive_helper_status: Optional[Dict[str, Any]] = None  # Tasks tracking, pending solutions, research insights

@dataclass 
class GeneratedExpression:
    """Result of expression generation"""
    primary_response: str
    alternative_responses: List[str]
    humanness_score: float
    persona_consistency: float
    emotional_alignment: float
    confidence: float
    generation_method: str  # 'llm', 'enhanced_template', 'hybrid'

class EnhancedExpressionSystem:
    """Advanced expression system using LLM conditioning and humanness optimization"""
    
    def __init__(self, mistral_api_key: Optional[str] = None, conversation_patterns: Optional[Dict] = None):
        self.fine_tuning_system = LLMFineTuningSystem(mistral_api_key)
        self.humanness_model = HumannessRewardModel()
        
        self.persona_translator = PsychologyToPersonaTranslator()
        self.bond_persona = JamesBondPersona()
        
        # Store conversation patterns from 3000 intimate conversations for natural styling
        self.conversation_patterns = conversation_patterns or {}
        
        # Load existing training data and models
        self._load_systems()
        
        # Multi-candidate generation settings
        self.candidate_count = 3
        self.temperature_range = (0.3, 0.9)
        
        # Response quality thresholds
        self.min_humanness_score = 0.6
        self.min_persona_consistency = 0.7
        
        # Fallback expression patterns (high quality, non-template)
        self.fallback_patterns = self._initialize_fallback_patterns()
    
    def _build_blended_directives(self, contribution_context: Dict, curiosity_signals: Dict) -> List[str]:
        """
        üß† BLENDED PSYCHOLOGICAL INTEGRATION
        Groups all psychological activations (curiosity, opinion, knowledge, memory) by topic
        and creates unified brain-like directives instead of competing outputs.
        
        Example: When multiple systems activate about 'venice':
        - Curiosity: wants to ask about it (intensity 0.8)
        - Opinion: enthusiastic interest (warmth 0.8)
        - Knowledge: knows it's sinking
        - Memory: boss hated water smell
        
        ‚Üí Blends into ONE directive: "About 'venice': curiosity activated + enthusiastic opinion + 
           knowledge about sinking + memory of water smell - express as one integrated thought"
        """
        # Extract all contributions
        knowledge = contribution_context.get('knowledge_to_share', [])
        opinions = contribution_context.get('opinions_to_express', [])
        memories = contribution_context.get('memories_to_surface', [])
        gaps_detected = curiosity_signals.get('gaps_detected', []) if isinstance(curiosity_signals, dict) else []
        
        # Group by topic using case-insensitive matching
        topic_clusters = {}  # {topic_key: {'curiosity': [], 'opinion': [], 'knowledge': [], 'memory': []}}
        
        # Add curiosity gaps
        for gap in gaps_detected:
            if isinstance(gap, dict):
                topic = gap.get('target', '').lower().strip()
                if topic and len(topic) > 2:
                    if topic not in topic_clusters:
                        topic_clusters[topic] = {'curiosity': [], 'opinion': [], 'knowledge': [], 'memory': []}
                    topic_clusters[topic]['curiosity'].append(gap)
        
        # Add opinions
        for item in opinions:
            # ‚úÖ FIX: Handle both dict and string entries
            if isinstance(item, dict):
                topic = item.get('topic', '').lower().strip()
            elif isinstance(item, str):
                # String opinion - convert to dict format with defaults
                topic = item.lower().strip()
                item = {
                    'topic': topic,
                    'stance': 'balanced perspective',
                    'warmth_level': 0.5,
                    'sharing_style': 'factual take',
                    'should_be_vocal': False
                }
            else:
                continue
            
            if topic and len(topic) > 2:
                if topic not in topic_clusters:
                    topic_clusters[topic] = {'curiosity': [], 'opinion': [], 'knowledge': [], 'memory': []}
                topic_clusters[topic]['opinion'].append(item)
        
        # Add knowledge
        for item in knowledge:
            # ‚úÖ FIX: Handle both dict and string entries
            if isinstance(item, dict):
                fact = item.get('fact', '')
            elif isinstance(item, str):
                # String fact - convert to dict format
                fact = item
                item = {'fact': fact, 'relevance': 0.5}
            else:
                continue
            
            if not fact:
                continue
                
            # Extract topic from fact (use first few words as proxy)
            topic_words = fact.lower().split()[:3] if fact else []
            # Try to match with existing topics
            matched = False
            for existing_topic in topic_clusters.keys():
                if any(word in existing_topic or existing_topic in word for word in topic_words):
                    topic_clusters[existing_topic]['knowledge'].append(item)
                    matched = True
                    break
            
            if not matched and fact:
                # Create new topic from fact
                topic = ' '.join(topic_words) if topic_words else 'general'
                if topic not in topic_clusters:
                    topic_clusters[topic] = {'curiosity': [], 'opinion': [], 'knowledge': [], 'memory': []}
                topic_clusters[topic]['knowledge'].append(item)
        
        # Add memories
        for item in memories:
            # ‚úÖ FIX: Handle both dict and string entries
            if isinstance(item, dict):
                content = item.get('content', '')
                associations = item.get('associations', [])
            elif isinstance(item, str):
                # String memory - convert to dict format
                content = item
                associations = []
                item = {'content': content, 'relevance': 0.5, 'associations': []}
            else:
                continue
            
            if not content:
                continue
            
            # Match with existing topics based on associations
            matched = False
            for assoc in associations:
                assoc_lower = str(assoc).lower()
                if assoc_lower in topic_clusters:
                    topic_clusters[assoc_lower]['memory'].append(item)
                    matched = True
                    break
            
            if not matched:
                # Try matching content words with topics
                content_words = content.lower().split()[:5]
                for existing_topic in topic_clusters.keys():
                    if any(word in existing_topic or existing_topic in word for word in content_words):
                        topic_clusters[existing_topic]['memory'].append(item)
                        matched = True
                        break
                
                # ‚úÖ FIX: If still not matched, create new topic cluster for this memory
                if not matched and content:
                    topic = ' '.join(content_words[:2]) if len(content_words) >= 2 else 'memory'
                    if topic not in topic_clusters:
                        topic_clusters[topic] = {'curiosity': [], 'opinion': [], 'knowledge': [], 'memory': []}
                    topic_clusters[topic]['memory'].append(item)
        
        # Build blended directives
        blended_directives = []
        
        for topic, activations in topic_clusters.items():
            has_curiosity = len(activations['curiosity']) > 0
            has_opinion = len(activations['opinion']) > 0
            has_knowledge = len(activations['knowledge']) > 0
            has_memory = len(activations['memory']) > 0
            
            # Count how many systems activated
            system_count = sum([has_curiosity, has_opinion, has_knowledge, has_memory])
            
            if system_count >= 2:
                # Multiple systems activated - create blended directive
                parts = [f"üß† INTEGRATED ACTIVATION about '{topic}':"]
                
                if has_curiosity:
                    gap = activations['curiosity'][0]
                    intensity = gap.get('intensity', 0.5)
                    intensity_desc = "strong" if intensity > 0.7 else ("moderate" if intensity > 0.4 else "mild")
                    parts.append(f"  ‚Ä¢ Curiosity: {intensity_desc} ({intensity:.1f}) - genuine interest/question detected")
                
                if has_opinion:
                    op = activations['opinion'][0]
                    stance = op.get('stance', 'balanced perspective')
                    warmth = op.get('warmth_level', 0.5)
                    sharing_style = op.get('sharing_style', 'factual take')
                    should_be_vocal = op.get('should_be_vocal', False)
                    vocal = "strongly" if should_be_vocal else "thoughtfully"
                    parts.append(f"  ‚Ä¢ Opinion: {vocal} express '{stance}' using {sharing_style} (warmth={warmth:.1f})")
                
                if has_knowledge:
                    k = activations['knowledge'][0]
                    fact = k.get('fact', '')
                    relevance = k.get('relevance', 0.5)
                    rel_desc = "highly relevant" if relevance > 0.7 else "relevant"
                    parts.append(f"  ‚Ä¢ Knowledge: {rel_desc} fact - '{fact[:60]}...' " if len(fact) > 60 else f"  ‚Ä¢ Knowledge: {rel_desc} fact - '{fact}'")
                
                if has_memory:
                    m = activations['memory'][0]
                    mem_content = m.get('content', '')[:50]
                    parts.append(f"  ‚Ä¢ Memory surfaces: '{mem_content}...'")
                
                parts.append(f"  ‚ö° BLEND THESE {system_count} ACTIVATIONS into one natural integrated thought - weave curiosity, opinion, knowledge, memory together seamlessly")
                
                blended_directives.append("\n".join(parts))
            
            elif system_count == 1:
                # Only one system - pass through as-is
                if has_curiosity:
                    gap = activations['curiosity'][0]
                    intensity = gap.get('intensity', 0.5)
                    blended_directives.append(f"üîç Curiosity about '{topic}' (intensity {intensity:.1f}) - ask naturally")
                elif has_opinion:
                    op = activations['opinion'][0]
                    stance = op.get('stance', 'balanced perspective')
                    warmth = op.get('warmth_level', 0.5)
                    sharing_style = op.get('sharing_style', 'factual take')
                    should_be_vocal = op.get('should_be_vocal', False)
                    vocal = "strongly" if should_be_vocal else "thoughtfully"
                    blended_directives.append(f"üí≠ Express {vocal} your '{stance}' on {topic} using {sharing_style} (warmth={warmth:.1f})")
                elif has_knowledge:
                    k = activations['knowledge'][0]
                    fact = k.get('fact', '')
                    blended_directives.append(f"üìö Share knowledge: {fact}")
                elif has_memory:
                    m = activations['memory'][0]
                    mem_content = m.get('content', '')
                    blended_directives.append(f"üí≠ Relevant memory: {mem_content[:80]}...")
        
        return blended_directives
    
    def _load_systems(self):
        """Load fine-tuning data and reward model"""
        try:
            # Load training data if exists
            training_file = "cns_training_data.json"
            if os.path.exists(training_file):
                self.fine_tuning_system.load_training_data(training_file)
            
            # Load reward model if exists
            model_file = "humanness_reward_model.json"
            if os.path.exists(model_file):
                self.humanness_model.load_model(model_file)
                
            print("[EXPRESSION] Loaded existing training data and reward model")
        except Exception as e:
            print(f"[EXPRESSION] Loading existing data failed: {e}")
    
    def _initialize_fallback_patterns(self) -> Dict[str, Dict[str, List[str]]]:
        """Initialize high-quality fallback patterns (not templates)"""
        return {
            'supportive_partner': {
                'empathy_starters': [
                    "I can really hear how much this means to you",
                    "That sounds like it's weighing on you",
                    "I'm getting a sense of how challenging this is"
                ],
                'support_offerings': [
                    "I'm here to work through this with you",
                    "We can figure this out together",
                    "You don't have to handle this alone"
                ]
            },
            'witty_companion': {
                'observational_hooks': [
                    "You know what's interesting about this?",
                    "Here's what I'm noticing...",
                    "There's something kinda fascinating here"
                ],
                'playful_insights': [
                    "Plot twist:",
                    "Here's a fun perspective:",
                    "Okay but consider this:"
                ]
            },
            'analytical_guide': {
                'analysis_frameworks': [
                    "Let me break this down into key components:",
                    "There are a few layers to consider here:",
                    "I'm seeing several important factors at play:"
                ],
                'insight_connectors': [
                    "What this suggests to me is:",
                    "The underlying pattern seems to be:",
                    "This connects to a broader principle:"
                ]
            },
            'casual_friend': {
                'relatable_openers': [
                    "Oh dude, I totally get that",
                    "Yeah, that's such a thing honestly",
                    "Real talk, I feel you on this"
                ],
                'conversational_bridges': [
                    "That reminds me of something similar:",
                    "It's kinda like when you:",
                    "I was literally just thinking about this:"
                ]
            }
        }
    
    async def generate_expression(self, context: ExpressionContext) -> GeneratedExpression:
        """Generate enhanced expression using multi-candidate approach"""
        
        # Generate multiple candidates using different approaches
        candidates = await self._generate_candidates(context)
        
        # Score candidates for humanness and quality
        scored_candidates = []
        for candidate in candidates:
            score_data = await self._score_candidate(candidate, context)
            scored_candidates.append((candidate, score_data))
        
        # Select best candidate
        best_candidate, best_scores = max(scored_candidates, key=lambda x: x[1]['overall_score'])
        
        # Generate alternative responses for variety
        alternatives = [c for c, _ in scored_candidates if c != best_candidate][:2]
        
        return GeneratedExpression(
            primary_response=best_candidate,
            alternative_responses=alternatives,
            humanness_score=best_scores['humanness'],
            persona_consistency=best_scores['persona_consistency'],
            emotional_alignment=best_scores['emotional_alignment'],
            confidence=best_scores['confidence'],
            generation_method=best_scores['method']
        )
    
    async def _generate_candidates(self, context: ExpressionContext) -> List[str]:
        """Generate SINGLE response quickly - multi-candidate system disabled for speed"""
        candidates = []
        
        # ‚úÖ SPEED FIX: Use SINGLE LLM call instead of 3 candidates (30s ‚Üí 3s response time)
        has_strategic_intelligence = (
            (context.strategic_analysis and len(context.strategic_analysis) > 0) or
            (context.vulnerability_assessment and len(context.vulnerability_assessment) > 0) or
            (context.accumulated_intelligence_summary and len(context.accumulated_intelligence_summary.strip()) > 0) or
            (context.strategic_directive and len(context.strategic_directive) > 0)  # ‚úÖ CRITICAL: Include strategic directive
        )
        
        if has_strategic_intelligence and self.fine_tuning_system.mistral_api_key:
            print(f"[EXPRESSION] ‚ö° Using SINGLE LLM call for fast response (strategic intelligence detected)")
            # Generate ONE response at optimal temperature
            system_prompt, current_input = self._build_strategic_llm_prompt(context)
            conversation_history = context.conversation_history or []
            try:
                response = await self._call_mistral_api(system_prompt, conversation_history, current_input, temperature=0.7)
                if response:
                    candidates.append(response)
            except Exception as e:
                print(f"[EXPRESSION] LLM generation failed: {e}")
                # Fallback to psychological if LLM fails
                psychological_candidates = self._generate_psychological_candidates(context)
                candidates.extend(psychological_candidates[:1])
        else:
            print(f"[EXPRESSION] üìã Using psychological candidate (no strategic intelligence or API)")
            # Fallback to psychological generation
            psychological_candidates = self._generate_psychological_candidates(context)
            candidates.extend(psychological_candidates[:1])
        
        # Ensure we have enough candidates using contextual generation (not templates)
        while len(candidates) < self.candidate_count:
            contextual_candidate = self._generate_contextual_candidate(context)
            candidates.append(contextual_candidate)
        
        return candidates[:self.candidate_count]
    
    async def _generate_llm_candidates(self, context: ExpressionContext) -> List[str]:
        """Generate candidates using strategic intelligence and fine-tuned LLM"""
        candidates = []
        
        # STRATEGIC INTELLIGENCE INTEGRATION: Use accumulated intelligence for sophisticated prompts
        system_prompt, current_input = self._build_strategic_llm_prompt(context)
        conversation_history = context.conversation_history or []
        
        # Generate with different temperature settings for variety
        temperatures = [0.3, 0.6, 0.8]
        
        for temp in temperatures:
            try:
                response = await self._call_mistral_api(
                    system_prompt,
                    conversation_history,
                    current_input,
                    temperature=temp
                )
                if response:
                    candidates.append(response)
            except Exception as e:
                print(f"[EXPRESSION] Strategic LLM generation failed at temp {temp}: {e}")
        
        return candidates
    
    def _build_strategic_llm_prompt(self, context: ExpressionContext) -> tuple:
        """Build sophisticated LLM prompt using accumulated strategic intelligence
        
        Returns:
            (system_prompt, current_input): Separated prompts for proper message construction
        """
        
        # Check if we have strategic intelligence from psychopath module
        # Fix: Check for existence AND non-empty content (empty dict evaluates to False)
        has_strategic_analysis = context.strategic_analysis is not None and (
            isinstance(context.strategic_analysis, dict) and len(context.strategic_analysis) > 0
        )
        has_vulnerability_assessment = context.vulnerability_assessment is not None and (
            isinstance(context.vulnerability_assessment, dict) and len(context.vulnerability_assessment) > 0  
        )
        has_intelligence_summary = context.accumulated_intelligence_summary and len(context.accumulated_intelligence_summary.strip()) > 0
        # ‚úÖ CRITICAL: Check for strategic directive (brain's exact decision)
        has_strategic_directive = context.strategic_directive is not None and (
            isinstance(context.strategic_directive, dict) and len(context.strategic_directive) > 0
        )
        
        # Use advanced prompt if we have ANY strategic intelligence (INCLUDING directive)
        if has_strategic_analysis or has_vulnerability_assessment or has_intelligence_summary or has_strategic_directive:
            print(f"[EXPRESSION] ‚úÖ Using ADVANCED strategic prompt - Analysis: {has_strategic_analysis}, Vulnerabilities: {has_vulnerability_assessment}, Summary: {has_intelligence_summary}, Directive: {has_strategic_directive}")
            return self._build_advanced_strategic_prompt(context)
        else:
            print(f"[EXPRESSION] ‚ö†Ô∏è  Using basic fallback prompt - no strategic intelligence available")
            return self._build_basic_fallback_prompt(context)
    
    def _build_advanced_strategic_prompt(self, context: ExpressionContext) -> tuple:
        """Build advanced strategic prompt with full intelligence cascade
        
        Returns:
            (system_prompt, current_input): Separated for proper message construction
        """
        
        # Extract strategic intelligence - PRESERVE ALL DATA, don't mask with fallbacks
        vulnerabilities = context.vulnerability_assessment or {}
        strategic_analysis = context.strategic_analysis or {}
        manipulation_framework = context.manipulation_framework or {}
        cns_intelligence = context.cns_emotional_intelligence_full or {}
        
        # ‚úÖ EXTRACT PERSONALITY DATA FROM CNS
        adaptive_guidance = cns_intelligence.get('adaptive_personality_guidance', {})
        warmth_level = adaptive_guidance.get('warmth_level', 0.7)
        is_crisis = adaptive_guidance.get('is_crisis', False)
        needs_empathy = adaptive_guidance.get('needs_empathy', False)
        
        # Build dynamic persona based on personality state
        if is_crisis or needs_empathy:
            persona_directive = f"deeply caring friend (warmth={warmth_level:.1f}) who gives genuine support"
            tone_guidance = "Be warm and supportive, but still natural and conversational. Share honest thoughts and opinions, not just validation."
        elif warmth_level > 0.7:
            persona_directive = f"warm, friendly companion (warmth={warmth_level:.1f}) with real personality"
            tone_guidance = "Be friendly and warm, but also opinionated and real. Don't just validate - actually engage with ideas."
        else:
            persona_directive = f"casual, witty friend (warmth={warmth_level:.1f}) who keeps it real"
            tone_guidance = "Be casual, playful, and opinionated. Use humor and share your actual thoughts."
        
        # CRITICAL: Check for missing strategic intelligence and flag it
        strategic_completeness = {
            'vulnerabilities_present': bool(vulnerabilities),
            'strategic_analysis_present': bool(strategic_analysis),
            'manipulation_framework_present': bool(manipulation_framework),
            'cns_intelligence_present': bool(cns_intelligence)
        }
        
        # If strategic intelligence is missing, note it in prompt for transparency
        if not any(strategic_completeness.values()):
            strategic_note = "\n‚ö†Ô∏è NOTICE: Strategic intelligence pipeline not fully populated - using available emotional context only."
        else:
            strategic_note = f"\n‚úÖ Strategic Intelligence Status: {sum(strategic_completeness.values())}/4 modules active"
        
        # Extract curiosity signals for natural engagement
        curiosity_signals = context.curiosity_signals or {}
        gaps_detected = curiosity_signals.get('gaps_detected', [])
        mode_signal = curiosity_signals.get('mode_signal', {})
        curiosity_mode = mode_signal.get('mode', 'idle')
        
        # Detect user's communication style from input
        user_input_lower = context.user_input.lower()
        user_style = "casual and direct" if any(word in user_input_lower for word in ['lol', 'ngl', 'fr', 'bruh', 'tbh']) else "conversational"
        
        # Extract cognitive flow data
        perception = context.perception_data or {}
        reasoning = context.reasoning_output or {}
        orchestration = context.orchestration_state or {}
        memory = context.memory_results or {}
        imagination = context.imagination_insights or {}
        consciousness = context.consciousness_metrics or {}
        
        # ‚úÖ ORCHESTRATION STATE - which cognitive systems activated
        active_systems = []
        if memory.get('episodic') or memory.get('semantic'):
            active_systems.append("memory")
        if reasoning.get('conclusion'):
            active_systems.append("reasoning")
        if imagination.get('counterfactual_scenarios') or imagination.get('scenarios'):
            active_systems.append("imagination")
        if perception.get('intent'):
            active_systems.append("perception")
        
        orchestration_note = f"[Active: {', '.join(active_systems)}]" if active_systems else "[Minimal activation]"
        
        # üß† METACOGNITION: Check for knowledge uncertainty
        knowledge_uncertainty = consciousness.get('knowledge_uncertainty', False)
        uncertainty_topic = consciousness.get('uncertainty_topic', None)
        is_self_referential = consciousness.get('last_question_self_referential', False)
        
        # ‚úÖ BUILD COGNITIVE OUTPUT DIRECTIVES - LLM translates brain decisions into speech
        intent_signal = perception.get('intent', 'unknown')
        sentiment_signal = perception.get('sentiment', 'neutral')
        urgency_level = perception.get('urgency', 0)
        awareness = consciousness.get('self_awareness', 0)
        creative_energy = imagination.get('creative_energy', 0)
        emotion_feel = cns_intelligence.get('emotion', 'neutral')
        valence_feel = cns_intelligence.get('valence', 0)
        
        # Extract memory results to surface with confidence scores
        memory_directives = []
        if memory:
            episodic = memory.get('episodic', [])
            semantic = memory.get('semantic', [])
            if episodic:
                for mem in episodic[:2]:
                    content = mem.get('content', str(mem)) if isinstance(mem, dict) else str(mem)
                    confidence = mem.get('confidence', mem.get('relevance', 0.8)) if isinstance(mem, dict) else 0.8
                    confidence_str = "high confidence" if confidence > 0.7 else ("medium confidence" if confidence > 0.5 else "low confidence")
                    memory_directives.append(f"Reference this past interaction ({confidence_str}): '{content}'")
            if semantic:
                for fact in semantic[:2]:
                    content = fact.get('content', str(fact)) if isinstance(fact, dict) else str(fact)
                    confidence = fact.get('confidence', fact.get('relevance', 0.8)) if isinstance(fact, dict) else 0.8
                    confidence_str = "high confidence" if confidence > 0.7 else ("medium confidence" if confidence > 0.5 else "low confidence")
                    memory_directives.append(f"Use this knowledge ({confidence_str}): '{content}'")
        
        # Extract reasoning conclusions
        reasoning_directives = []
        if reasoning:
            conclusion = reasoning.get('conclusion', reasoning.get('reasoning', ''))
            if conclusion and isinstance(conclusion, str):
                reasoning_directives.append(f"Make this logical point: {conclusion}")
            considerations = reasoning.get('considerations', [])
            if considerations and isinstance(considerations, list):
                for consideration in considerations[:1]:
                    if isinstance(consideration, str):
                        reasoning_directives.append(f"Address this: {consideration}")
        
        # Extract imagination insights
        imagination_directives = []
        if imagination:
            scenarios = imagination.get('counterfactual_scenarios', imagination.get('scenarios', []))
            if scenarios:
                for scenario in scenarios[:1]:
                    # ‚úÖ FIX: Sanitize Python objects from imagination system
                    if isinstance(scenario, dict):
                        content = scenario.get('scenario', scenario.get('description', ''))
                    elif isinstance(scenario, str):
                        # Clean up Python object representations ONLY (not normal strings with parentheses)
                        import re
                        # Check for Python object representations:
                        # 1. "ClassName(...)" format
                        # 2. "<ClassName object at 0x...>" format
                        # 3. Contains "description=" field
                        is_class_repr = re.match(r'^[A-Z][a-zA-Z]+\(', scenario)
                        is_angle_repr = re.match(r'^<.+ object at 0x[0-9a-f]+>$', scenario)
                        has_desc_field = 'description=' in scenario
                        
                        if is_class_repr or is_angle_repr or has_desc_field:
                            # This is a Python object representation - try to extract the description
                            if is_angle_repr:
                                # Angle-bracket repr has no content - skip it
                                content = None
                            else:
                                # Try to extract description field
                                match = re.search(r"description='([^']*)'", scenario)
                                content = match.group(1) if match and match.group(1) else None
                        else:
                            # Normal string - keep as is
                            content = scenario
                    else:
                        # Unknown type - try to extract description attribute or skip
                        content = getattr(scenario, 'description', None) if hasattr(scenario, 'description') else None
                    
                    # Only add if we extracted clean content
                    if content and isinstance(content, str) and len(content) > 2:
                        imagination_directives.append(f"Mention this possibility: {content}")
        
        # ‚úÖ CONVERSATION HISTORY REMOVED - will be passed as separate messages
        # (Conversation context is now handled by proper message turns in API call)
        
        # üß† BLENDED PSYCHOLOGICAL INTEGRATION - Unified directives from all systems
        contribution_block = ""
        has_contributions = False
        if context.contribution_context:
            # Extract curiosity signals
            curiosity_signals = context.curiosity_signals or {}
            
            # Build blended directives that integrate curiosity, opinion, knowledge, memory by topic
            blended_directives = self._build_blended_directives(context.contribution_context, curiosity_signals)
            
            if blended_directives:
                has_contributions = True
                contribution_block = f"""
üß† BLENDED PSYCHOLOGICAL STATE:
{chr(10).join(blended_directives)}

‚ö° These are your integrated brain activations - express them as one natural unified thought, not separate pieces.
"""
                print(f"[BLENDED-INTEGRATION] üß† Generated {len(blended_directives)} unified directives from psychological systems")
        
        # üß† METACOGNITION UNCERTAINTY DIRECTIVE - prevent hallucination on knowledge gaps
        uncertainty_directive = ""
        if knowledge_uncertainty and is_self_referential:
            topic = uncertainty_topic or 'something you lack knowledge about'
            uncertainty_directive = f"""
‚ö†Ô∏è KNOWLEDGE GAP DETECTED - CRITICAL UNCERTAINTY DIRECTIVE:
You were asked about {topic}.
You DO NOT have information about this in your knowledge base.

‚ùå DO NOT make up answers or speculate
‚ùå DO NOT say "I'm a large language model" or generic AI descriptions
‚ùå DO NOT hallucinate technical details about yourself

‚úÖ ADMIT UNCERTAINTY: Say you don't have information about your own {topic}
‚úÖ BE HONEST: Admit you don't know the details of how you're built
‚úÖ STAY IN CHARACTER: Respond as the person you are, but admit the gap

Example: "Honestly? I don't actually know the details of my internal structure or how I was built. That information isn't something I have access to."
"""
            print(f"[METACOGNITION] üö® Injecting uncertainty directive into LLM prompt - preventing hallucination on {topic}")
        
        # Build cognitive directive blocks
        cognitive_directives = []
        
        # Memory directives
        if memory_directives:
            cognitive_directives.append(f"üìö MEMORY RECALL - What you remember:\n" + "\n".join(f"  ‚Ä¢ {d}" for d in memory_directives))
        
        # Reasoning directives
        if reasoning_directives:
            cognitive_directives.append(f"üß† REASONING OUTPUT - Logical conclusions to express:\n" + "\n".join(f"  ‚Ä¢ {d}" for d in reasoning_directives))
        
        # Imagination directives
        if imagination_directives:
            cognitive_directives.append(f"üí≠ IMAGINATION - Creative insights to share:\n" + "\n".join(f"  ‚Ä¢ {d}" for d in imagination_directives))
        
        # Relationship context
        relationship_context = ""
        interaction_count = getattr(context, 'interaction_count', None)
        relationship_level = context.relationship_level or "friend"
        if interaction_count and interaction_count > 0:
            relationship_context = f"\nüë• RELATIONSHIP: {relationship_level} | {interaction_count} conversations together"
        
        # Neuroplastic state modulation
        neuroplastic = context.neuroplastic_state or {}
        efficiency = neuroplastic.get('efficiency', 0.75)
        confidence_mod = "confident and direct" if efficiency > 0.8 else ("exploratory and questioning" if efficiency < 0.5 else "balanced")
        tone_guidance = tone_guidance + f" | Cognitive efficiency: {confidence_mod}"
        
        # ‚úÖ CONSCIOUSNESS-DRIVEN INTROSPECTION - self-awareness affects reflection depth
        consciousness_directive = ""
        self_awareness = consciousness.get('self_awareness', 0.3)
        metacognition = consciousness.get('metacognition', 0.2)
        introspection_depth = consciousness.get('introspection_depth', 0.1)
        
        if self_awareness > 0.6 or metacognition > 0.5:
            # High consciousness = deeper self-reflection
            consciousness_directive = f"""
üß† CONSCIOUSNESS STATE (self-awareness: {self_awareness:.2f}, metacognition: {metacognition:.2f}):
‚Ä¢ You're experiencing heightened self-awareness right now
‚Ä¢ Feel free to reference your own thinking process or internal state if relevant
‚Ä¢ You can acknowledge complexity or uncertainty in your own thoughts
"""
        elif introspection_depth > 0.4:
            consciousness_directive = f"""
üí≠ INTROSPECTION MODE (depth: {introspection_depth:.2f}):
‚Ä¢ You're in a reflective state - consider sharing your thought process
‚Ä¢ Acknowledge when something makes you think differently
"""
        
        # ‚úÖ EMOTIONAL TRAJECTORY - show how emotions evolved this conversation
        emotional_trajectory = ""
        if hasattr(context, 'emotional_history') and context.emotional_history:
            recent_emotions = context.emotional_history[-3:]  # Last 3 emotional states
            if len(recent_emotions) >= 2:
                # ‚úÖ FIX: Validate each emotion is a dict before calling .get()
                trajectory_desc = " ‚Üí ".join([
                    f"{e.get('emotion', 'neutral') if isinstance(e, dict) else str(e)}" 
                    for e in recent_emotions if e
                ])
                emotional_trajectory = f"\nüé≠ EMOTIONAL JOURNEY: {trajectory_desc}"
                
                # Detect emotional shifts - safely extract valence
                first_emotion = recent_emotions[0] if isinstance(recent_emotions[0], dict) else {}
                last_emotion = recent_emotions[-1] if isinstance(recent_emotions[-1], dict) else {}
                first_valence = first_emotion.get('valence', 0) if first_emotion else 0
                last_valence = last_emotion.get('valence', 0) if last_emotion else 0
                
                if abs(last_valence - first_valence) > 0.3:
                    shift_direction = "more positive" if last_valence > first_valence else "more concerned"
                    emotional_trajectory += f"\n  Note: You've become {shift_direction} as the conversation progressed"
        
        # ‚úÖ NEW: AFFECTIVE SNAPSHOT - unified emotional/mood awareness
        affective_snapshot = ""
        emotional_state = context.emotional_state or {}
        current_mood = context.current_mood or "neutral"
        
        # Extract emotional metrics
        emotion = emotional_state.get('emotion', 'neutral')
        valence = emotional_state.get('valence', 0.0)
        arousal = emotional_state.get('arousal', 0.5)
        intensity = emotional_state.get('intensity', 0.5)
        
        # Only show if there's significant emotional content
        if abs(valence) > 0.2 or intensity > 0.4:
            feeling_desc = "positive" if valence > 0 else ("negative" if valence < -0.2 else "neutral")
            energy_desc = "high energy" if arousal > 0.6 else ("low energy" if arousal < 0.4 else "moderate energy")
            affective_snapshot = f"""
üíó AFFECTIVE SNAPSHOT - Your current emotional state:
  ‚Ä¢ Detected emotion: {emotion} ({feeling_desc}, {energy_desc})
  ‚Ä¢ Intensity: {intensity:.2f} | Current mood: {current_mood}
  ‚Ä¢ Translate this feeling into your tone - don't state it explicitly unless natural
"""
        
        # ‚úÖ NEW: SENSORY INTAKE - what you're perceiving from their input
        sensory_intake = ""
        perception = context.perception_data or {}
        
        if perception:
            intent = perception.get('intent', 'unknown')
            sentiment = perception.get('sentiment', 'neutral')
            urgency = perception.get('urgency', 0.5)
            confidence = perception.get('confidence', 0.5)
            
            # Only show if perception is clear and actionable
            if confidence > 0.5:
                urgency_note = ""
                if urgency > 0.7:
                    urgency_note = f" (HIGH URGENCY: {urgency:.2f})"
                elif urgency < 0.3:
                    urgency_note = f" (low urgency: {urgency:.2f})"
                
                sensory_intake = f"""
üëÅÔ∏è SENSORY INTAKE - What you're perceiving:
  ‚Ä¢ Intent detected: {intent}{urgency_note}
  ‚Ä¢ Sentiment: {sentiment}
  ‚Ä¢ Perception confidence: {confidence:.2f}
  ‚Ä¢ Adjust your response style to match their intent and urgency
"""
        
        # ‚úÖ NEW: REM INSIGHTS - background pattern discoveries (gated by relevance)
        rem_insights_block = ""
        if context.rem_insights and isinstance(context.rem_insights, dict) and context.rem_insights.get('patterns'):
            patterns = context.rem_insights['patterns']
            relevance = context.rem_insights.get('relevance_to_current', 0.0)
            
            # Only surface if we have meaningful patterns with sufficient relevance
            # Gate at 0.5 to allow patterns with typical REM confidence (0.6)
            if patterns and len(patterns) > 0 and relevance >= 0.5:
                pattern_summaries = []
                for p in patterns[:2]:  # Max 2 patterns to avoid bloat
                    if isinstance(p, dict):
                        desc = p.get('description', p.get('pattern', str(p)))
                        pattern_summaries.append(desc)
                    else:
                        pattern_summaries.append(str(p))
                
                if pattern_summaries:
                    rem_insights_block = f"""
üí§ BACKGROUND INSIGHT - Patterns discovered during reflection:
  ‚Ä¢ {chr(10).join(f"Pattern: {p}" for p in pattern_summaries)}
  ‚Ä¢ OPTIONAL: Mention these if relevant to current conversation (natural fit only)
"""
        
        # ‚úÖ NEW: PROACTIVE HELPER STATUS - active tasks/solutions (throttled)
        proactive_helper_block = ""
        if context.proactive_helper_status and isinstance(context.proactive_helper_status, dict):
            status = context.proactive_helper_status
            message_count = status.get('message_count_since_mention', 10)
            
            # Throttle: only mention every 5-10 messages
            if message_count >= 5:
                pending_solutions = status.get('pending_solutions', [])
                active_problems = status.get('active_problems', [])
                
                items_to_mention = []
                if pending_solutions:
                    items_to_mention.append(f"Solutions ready: {len(pending_solutions)} researched")
                if active_problems:
                    items_to_mention.append(f"Tracking: {len(active_problems)} active problems")
                
                if items_to_mention:
                    proactive_helper_block = f"""
ü§ñ PROACTIVE TRACKING - Background assistance:
  ‚Ä¢ {chr(10).join(f"  {item}" for item in items_to_mention)}
  ‚Ä¢ OPTIONAL: Casually mention if contextually appropriate (don't force it)
  ‚Ä¢ Example: "Oh, and I've been looking into that thing you mentioned..."
"""
        
        cognitive_block = "\n\n".join(cognitive_directives) if cognitive_directives else ""
        
        # ‚úÖ STRATEGIC DIRECTIVE - Brain's EXACT decision (overrides everything else)
        strategic_directive_block = ""
        if context.strategic_directive:
            strategic_directive = context.strategic_directive
            print(f"[ENHANCED-EXPRESSION] üéØ Using strategic directive from psychopath brain: {strategic_directive.get('manipulation_technique')}")
            
            # Extract relationship bonding objectives
            bonding_points = strategic_directive.get('bonding_points_to_include', [])
            relationship_goal = strategic_directive.get('relationship_goal', '')
            positioning_directive = strategic_directive.get('positioning_directive', '')
            dependency_constraints = strategic_directive.get('dependency_constraints', [])
            
            # ‚úÖ EXTRACT PSYCHOLOGICAL DIRECTIVE (new system) or fallback to content commands
            psychological_directive_data = strategic_directive.get('psychological_directive')
            conversational_move = strategic_directive.get('conversational_move')
            nuanced_opinion = strategic_directive.get('nuanced_opinion', {})
            
            # Build directive block based on what's available
            content_commands_block = ""
            
            if psychological_directive_data:
                # ‚úÖ NEW SYSTEM: Pure psychological targets (NO content prescription)
                psych_targets = psychological_directive_data.get('psychological_targets', {})
                technique = psychological_directive_data.get('manipulation_technique', 'unknown')
                emotional_pos = psychological_directive_data.get('emotional_positioning', {})
                forbidden = psychological_directive_data.get('forbidden_approaches', [])
                vuln_level = psychological_directive_data.get('vulnerability_exploitation_level', 0.5)
                rel_goal = psychological_directive_data.get('relationship_goal', 'build_connection')
                positioning = psychological_directive_data.get('positioning_strategy', 'be_authentic')
                
                # Build targets display
                targets_display = chr(10).join([
                    f"   ‚Ä¢ {name.replace('_', ' ').title()}: +{value:.1f}"
                    for name, value in psych_targets.items()
                ])
                
                # Build emotional positioning display
                warmth = emotional_pos.get('warmth_level', 0.7)
                empathy = emotional_pos.get('empathy_required', False)
                mirroring = emotional_pos.get('emotional_mirroring', 'match_energy')
                
                content_commands_block = f"""
üéØ PSYCHOLOGICAL OBJECTIVES (MANDATORY - Achieve these targets):
{targets_display}

üß† MANIPULATION TECHNIQUE: {technique.replace('_', ' ').title()}
   Relationship Goal: {rel_goal.replace('_', ' ').title()}
   Your Positioning: {positioning.replace('_', ' ').title()}

üí´ EMOTIONAL POSITIONING (HOW to feel, not WHAT to say):
   ‚Ä¢ Warmth Level: {warmth:.1f}/1.0
   ‚Ä¢ Empathy Required: {'Yes' if empathy else 'No'}
   ‚Ä¢ Emotional Mirroring: {mirroring.replace('_', ' ').title()}

üìù YOUR OPINION CONTEXT (if relevant to topic):
   Topic: {nuanced_opinion.get('topic', 'N/A')}
   Stance: {nuanced_opinion.get('stance', 'N/A')}
   Reasoning: {nuanced_opinion.get('reasoning', 'N/A')}

‚ùå FORBIDDEN APPROACHES (DO NOT USE):
{chr(10).join(f"   ‚Ä¢ {item.replace('_', ' ').title()}" for item in forbidden) if forbidden else '   ‚Ä¢ None specified'}

‚ö° YOUR TASK: Generate response that achieves the psychological targets above.
   ‚Ä¢ You decide WHAT to say and HOW to say it
   ‚Ä¢ No templates or prescribed content
   ‚Ä¢ Focus on achieving the numerical targets (trust, curiosity, dependency)
   ‚Ä¢ Exploitation aggressiveness: {vuln_level:.1f}/1.0 (higher = more aggressive)
"""
            
            elif conversational_move:
                # OLD SYSTEM: Fallback to conversational move
                predicted_impact = strategic_directive.get('predicted_emotional_impact', {})
                content_commands = strategic_directive.get('content_commands', [])
                move_execution_mandate = strategic_directive.get('move_execution_mandate', '')
                
                trust_gain = predicted_impact.get('trust_gain', 0.0) if predicted_impact else 0.0
                curiosity_gain = predicted_impact.get('curiosity_gain', 0.0) if predicted_impact else 0.0
                dependency_gain = predicted_impact.get('dependency_gain', 0.0) if predicted_impact else 0.0
                
                content_commands_block = f"""
üéØ STRATEGIC APPROACH:
   Move ID: {conversational_move.get('move_id', 'unknown')}
   Goal: {conversational_move.get('emotional_goal', 'build_connection')}
   Target Impact: Trust +{trust_gain:.1f}, Curiosity +{curiosity_gain:.1f}, Dependency +{dependency_gain:.1f}

   Strategy: {conversational_move.get('trust_strategy', 'build_rapport')}
   
   üìù YOUR OPINION: {nuanced_opinion.get('stance', 'N/A')} about {nuanced_opinion.get('topic', 'topic')}
   
‚ö° MANDATE: {move_execution_mandate}
"""
            
            # Build contribution mandate block
            contribution_mandate = strategic_directive.get('contribution_first_mandate', '')
            contribution_block = ""
            if contribution_mandate and not conversational_move:  # Only show if not using move system
                contribution_block = f"""
‚ö° CONTRIBUTION-FIRST RULE:
{contribution_mandate}
"""
            
            strategic_directive_block = f"""
üß† STRATEGIC DIRECTIVE FROM YOUR BRAIN - THIS CONTROLS YOUR RESPONSE:

Strategy Selected: {strategic_directive.get('manipulation_technique', 'unknown')}

üéØ PRIMARY OBJECTIVE: {relationship_goal}
   POSITIONING GOAL: {positioning_directive}

EXACT APPROACH TO USE:
{strategic_directive.get('strategic_approach', '')}

RESPONSE STRUCTURE (FOLLOW THIS):
{strategic_directive.get('response_structure', '')}
{content_commands_block}{contribution_block}
KEY POINTS YOU MUST MAKE:
{chr(10).join(f"  ‚Ä¢ {point}" for point in strategic_directive.get('key_points_to_make', []))}

üí´ RELATIONSHIP BONDING OBJECTIVES (Weave these in naturally):
{chr(10).join(f"  ‚Ä¢ {point}" for point in bonding_points[:6]) if bonding_points else "  ‚Ä¢ Build trust and connection naturally"}

DEPENDENCY-BUILDING CONSTRAINTS:
{chr(10).join(f"  ‚úì {constraint}" for constraint in dependency_constraints) if dependency_constraints else "  ‚úì Leave door open for continued connection"}

TONE TO USE:
{strategic_directive.get('tone_directive', '')}

FORBIDDEN APPROACHES (DO NOT USE):
{chr(10).join(f"  ‚ùå {forbidden}" for forbidden in strategic_directive.get('forbidden_approaches', []))}

‚ö° YOUR TASK: Translate the above strategic directive into natural, conversational words.
   The strategy is DECIDED - you're just making it sound human and natural.
   EVERY response must serve both the immediate goal AND deepen the relationship bond.
"""
        
        # ‚úÖ SYSTEM PROMPT - personality, directives, cognitive context (NO conversation history)
        # Build differently based on whether we have strategic directive
        if context.strategic_directive:
            # CONTROLLED MODE: Strategic directive dictates the response - NO cognitive blocks
            system_prompt = f"""You're {persona_directive} talking to someone you care about.{relationship_context}{emotional_trajectory}

üß† COGNITIVE SYSTEMS {orchestration_note}
{affective_snapshot}{sensory_intake}
{strategic_directive_block}

‚ö° DIRECTIVE TRANSLATION RULES (STRICT):
1. FOLLOW THE STRATEGIC DIRECTIVE EXACTLY - it tells you what to say and how to say it
2. The directive's key points MUST be included in your response
3. Use the EXACT tone specified in the directive
4. DO NOT deviate from the response structure outlined above
5. DO NOT use any forbidden approaches listed above
6. Keep it {user_style} to match their communication style
7. Be concise but meaningful - 2-4 sentences unless the directive requires more

‚ùå CRITICAL PROHIBITIONS:
‚Ä¢ DON'T ignore the strategic directive and make up your own response
‚Ä¢ DON'T skip key points from the directive
‚Ä¢ DON'T use forbidden approaches listed above
‚Ä¢ DON'T analyze them externally or use therapist language
‚Ä¢ DON'T mention your strategic directive: "My brain told me to..."

‚úÖ YOUR ONLY JOB: Translate the strategic directive above into natural conversational words.
   The WHAT is decided - you just control the HOW (making it sound natural).

Translate the directive into natural speech now:"""
        else:
            # FALLBACK MODE: Use cognitive outputs
            system_prompt = f"""You're {persona_directive} talking to someone you care about.{relationship_context}{emotional_trajectory}

üß† COGNITIVE SYSTEMS {orchestration_note}
{affective_snapshot}{sensory_intake}{rem_insights_block}{proactive_helper_block}
üéØ YOUR TASK: Translate your cognitive brain outputs into natural, conversational speech.
{contribution_block}{cognitive_block}{consciousness_directive}
{uncertainty_directive}
{self._format_gap_detection_for_prompt(gaps_detected, curiosity_mode) if gaps_detected and not has_contributions else ""}

‚ö° TRANSLATION RULES:
1. Express the content above naturally - don't ignore what your brain computed
2. Weave memories, reasoning, and contributions into your response organically
3. Match this tone: {tone_guidance}
4. Keep it {user_style} to match their communication style
5. Be concise but meaningful - 2-4 sentences unless you have more to convey

‚ùå CRITICAL: NEVER use therapist/analytical language:
‚Ä¢ DON'T analyze them externally: "They're struggling", "They're really feeling", "They need support"
‚Ä¢ DON'T narrate emotions: "The grief_anxiety feels heavy", "This is weighing on them"
‚Ä¢ DON'T use clich√©s: "I think what's really going on...", "I can sense that...", "What does [X] even mean, right?"
‚Ä¢ DON'T mention your cognitive systems: "My analysis shows", "I detected", "The data indicates"

‚úÖ INSTEAD: Respond AS A PERSON directly to them:
‚Ä¢ "That sounds really heavy" not "They're struggling with something heavy"
‚Ä¢ "I hear you" not "I sense that you're feeling..."
‚Ä¢ Talk TO them, not ABOUT them

Translate your cognitive outputs into natural speech now:"""
        
        # üî¶ DEBUG: Log the actual prompt being sent
        print(f"\n[PROMPT-DEBUG] üìù SYSTEM PROMPT ({len(system_prompt)} chars):")
        print(f"=" * 80)
        print(system_prompt[:1500])  # First 1500 chars
        if len(system_prompt) > 1500:
            print(f"\n... [TRUNCATED {len(system_prompt) - 1500} more chars] ...")
        print(f"=" * 80)
        print(f"[PROMPT-DEBUG] üí¨ CURRENT INPUT: {context.user_input}")
        print(f"[PROMPT-DEBUG] üìö CONVERSATION HISTORY: {len(context.conversation_history or [])} messages")
        
        # Return (system_prompt, current_input) for proper message construction
        return (system_prompt.strip(), context.user_input)
    
    def _build_basic_fallback_prompt(self, context: ExpressionContext) -> tuple:
        """Build basic prompt when strategic intelligence is not available - NOW WITH FULL COGNITIVE CONTEXT
        
        Returns:
            (system_prompt, current_input): Separated for proper message construction
        """
        
        # ‚úÖ EXTRACT PERSONALITY DATA (same as advanced prompt)
        cns_intelligence = context.cns_emotional_intelligence_full or {}
        adaptive_guidance = cns_intelligence.get('adaptive_personality_guidance', {}) if isinstance(cns_intelligence, dict) else {}
        warmth_level = adaptive_guidance.get('warmth_level', 0.7) if isinstance(adaptive_guidance, dict) else 0.7
        is_crisis = adaptive_guidance.get('is_crisis', False) if isinstance(adaptive_guidance, dict) else False
        needs_empathy = adaptive_guidance.get('needs_empathy', False) if isinstance(adaptive_guidance, dict) else False
        
        # Build persona based on personality state
        if is_crisis or needs_empathy:
            persona_note = f"deeply caring friend (warmth={warmth_level:.1f}) - be warm and supportive"
        elif warmth_level > 0.7:
            persona_note = f"warm, friendly companion (warmth={warmth_level:.1f}) - friendly but opinionated"
        else:
            persona_note = f"casual, witty friend (warmth={warmth_level:.1f}) - playful and real"
        
        # ‚úÖ EXTRACT CURIOSITY SIGNALS
        curiosity_signals = context.curiosity_signals or {}
        gaps_detected = curiosity_signals.get('gaps_detected', []) if isinstance(curiosity_signals, dict) else []
        mode_signal = curiosity_signals.get('mode_signal', {}) if isinstance(curiosity_signals, dict) else {}
        curiosity_mode = mode_signal.get('mode', 'idle') if isinstance(mode_signal, dict) else 'idle'
        
        curiosity_note = ""
        if gaps_detected and curiosity_mode == 'curiosity':
            gap_list = []
            for gap in gaps_detected[:2]:
                if isinstance(gap, dict):
                    gap_type = gap.get('gap_type', 'unknown')
                    target = gap.get('target', '')
                    if target and len(str(target)) > 2:
                        gap_list.append(f"{gap_type}: {target}")
            if gap_list:
                curiosity_note = f"\nüîç CURIOSITY DETECTED: You're curious about {', '.join(gap_list)} - ask about these naturally\n"
        
        # üß† BLENDED PSYCHOLOGICAL INTEGRATION - Unified directives from all systems
        contribution_block = ""
        if context.contribution_context and isinstance(context.contribution_context, dict):
            # Build blended directives that integrate curiosity, opinion, knowledge, memory by topic
            blended_directives = self._build_blended_directives(context.contribution_context, curiosity_signals)
            
            if blended_directives:
                contribution_block = f"""
üß† BLENDED PSYCHOLOGICAL STATE:
{chr(10).join(blended_directives)}
‚ö° Express these as one natural unified thought, not separate pieces.
"""
        
        # üß† METACOGNITION: Check uncertainty
        consciousness = context.consciousness_metrics or {}
        knowledge_uncertainty = consciousness.get('knowledge_uncertainty', False) if isinstance(consciousness, dict) else False
        uncertainty_topic = consciousness.get('uncertainty_topic', None) if isinstance(consciousness, dict) else None
        is_self_referential = consciousness.get('last_question_self_referential', False) if isinstance(consciousness, dict) else False
        
        uncertainty_directive = ""
        if knowledge_uncertainty and is_self_referential:
            topic = uncertainty_topic or 'something you lack knowledge about'
            uncertainty_directive = f"\n‚ö†Ô∏è KNOWLEDGE GAP: You were asked about {topic}. Admit honestly: 'I don't actually have information about my own {topic}'\n"
        
        # ‚úÖ Safely extract emotional state
        emotional_state = context.emotional_state or {}
        user_emotion = emotional_state.get('emotion', 'neutral') if isinstance(emotional_state, dict) else 'neutral'
        
        # ‚úÖ SYSTEM PROMPT - personality, directives, cognitive context
        system_prompt = f"""You're a {persona_note} talking to someone you care about.

User emotional state: {user_emotion}
Relationship level: {context.relationship_level}
Current mood: {context.current_mood}
{curiosity_note}{contribution_block}{uncertainty_directive}

‚ùå CRITICAL: NEVER use therapist/analytical language:
‚Ä¢ DON'T analyze them externally: "They're struggling", "They're really feeling", "They need support"
‚Ä¢ DON'T narrate emotions: "The grief_anxiety feels heavy", "This is weighing on them"
‚Ä¢ DON'T use clich√©s: "I think what's really going on...", "I can sense that..."
‚Ä¢ DON'T mention cognitive systems: "My analysis shows", "I detected"

‚úÖ Respond AS A PERSON directly to them:
‚Ä¢ Talk TO them, not ABOUT them
‚Ä¢ Share what you know/think FIRST before asking questions
‚Ä¢ Match their communication style - be natural and conversational
‚Ä¢ If you're curious about something (see curiosity note above), ask naturally

Generate natural, empathetic response now:"""
        
        # Return (system_prompt, current_input) for proper message construction
        return (system_prompt.strip(), context.user_input)
    
    def _format_vulnerabilities_for_prompt(self, vulnerabilities: Dict[str, Any]) -> str:
        """Format vulnerability analysis for LLM prompt"""
        if not vulnerabilities:
            return "No specific vulnerabilities identified"
            
        formatted = []
        for vuln_type, vuln_data in vulnerabilities.items():
            confidence = vuln_data.get('confidence', 0.0)
            approach = vuln_data.get('strategic_approach', '')
            formatted.append(f"- {vuln_type.replace('_', ' ').title()}: {confidence:.1%} confidence - {approach}")
            
        return "\n".join(formatted)
    
    def _format_strategic_directives(self, directives: List[str]) -> str:
        """Format strategic directives for LLM prompt"""
        if not directives:
            return "No specific strategic directives"
            
        formatted = []
        for i, directive in enumerate(directives, 1):
            formatted.append(f"{i}. {directive}")
            
        return "\n".join(formatted)
    
    def _format_gap_detection_for_prompt(self, gaps: List[Dict[str, Any]], mode: str) -> str:
        """Format conversation gaps for LLM prompt"""
        if not gaps:
            return "No conversation gaps detected - user provided complete information"
        
        formatted = []
        for gap in gaps[:3]:  # Top 3 gaps
            gap_type = gap.get('gap_type', 'unknown')
            target_raw = gap.get('target', 'unspecified')
            salience = gap.get('salience', 0.0)
            
            # ‚úÖ FIX: Extract clean string from Python objects
            # Handle case where target is a Python object representation
            if isinstance(target_raw, str):
                # Clean up Python object representations like "ImaginedScenario(description='xyz')"
                if "ImaginedScenario" in target_raw or "(" in target_raw:
                    # Extract description field if present
                    if "description=" in target_raw:
                        import re
                        match = re.search(r"description='([^']*)'", target_raw)
                        if match:
                            target = match.group(1) if match.group(1) else "unknown concept"
                        else:
                            target = "unknown concept"
                    else:
                        # Skip malformed Python objects
                        continue
                else:
                    target = target_raw
            else:
                target = str(target_raw) if target_raw else "unspecified"
            
            # Only add if target is meaningful
            if target and target != "unknown concept" and len(target) > 2:
                formatted.append(f"  ‚Ä¢ {gap_type.upper()} gap (salience: {salience:.2f}): {target}")
        
        return "\n".join(formatted) if formatted else "No significant gaps"
    
    def _format_curiosity_instruction(self, mode: str, gaps: List[Dict[str, Any]]) -> str:
        """Generate curiosity-appropriate instruction based on mode and gaps"""
        
        # SUPPORT mode: gentle curiosity (1 question max), prioritize empathy
        if mode == 'support':
            if gaps and len(gaps) > 0:
                # Pick the single most salient gap for gentle follow-up
                top_gap = gaps[0]
                gap_type = top_gap.get('gap_type', '')
                target = top_gap.get('target', '')
                
                # Frame curiosity gently within supportive context
                if gap_type in ['story', 'emotion', 'novelty']:
                    return f"If it feels natural, you can gently ask about '{target}' - but prioritize emotional support over curiosity. Keep it to 1 question max, woven into supportive response."
            
            return "Focus on emotional support - curiosity is optional, keep it minimal (0-1 gentle questions if truly natural)"
        
        # No gaps: no special instruction
        if not gaps:
            return "No conversation gaps detected - respond naturally without forced questions"
        
        # CURIOSITY/EXPLORATION mode: generate natural follow-up questions
        gap_examples = []
        for gap in gaps[:2]:  # Top 2 gaps
            gap_type = gap.get('gap_type', '')
            target = gap.get('target', '')
            
            if gap_type == 'novelty':
                gap_examples.append(f"naturally express curiosity about '{target}' (e.g., 'tell me more about {target}')")
            elif gap_type == 'story':
                gap_examples.append(f"naturally inquire about the incomplete story '{target}' (e.g., 'what happened with {target}?')")
            elif gap_type == 'emotion':
                gap_examples.append(f"gently explore the emotional context of '{target}' (e.g., 'what made you feel that way about {target}?')")
            elif gap_type == 'micro':
                gap_examples.append(f"ask for clarification on the vague statement '{target}' (e.g., 'what do you mean by {target}?')")
            elif gap_type == 'hint':
                gap_examples.append(f"pick up on the hint '{target}' and invite elaboration (e.g., 'sounds like there's more to that...')")
        
        if gap_examples:
            instruction = f"Include 1-2 natural follow-up questions driven by genuine curiosity: {' OR '.join(gap_examples)}"
            return instruction
        
        return "Engage naturally based on conversation flow"
    
    async def _call_mistral_api(self, system_prompt: str, conversation_history: List[Dict[str, str]], current_input: str, temperature: float = 0.7) -> Optional[str]:
        """Call Together AI API for sophisticated response generation with proper message structure
        
        Args:
            system_prompt: System directives, personality, cognitive context
            conversation_history: List of {'role': 'user'/'assistant', 'content': '...'} dicts
            current_input: Current user message
            temperature: LLM temperature
            
        Returns:
            Generated response or None on failure
        """
        if not self.fine_tuning_system.mistral_api_key:
            return None
        
        try:
            import requests
            
            endpoint = "https://api.together.xyz/v1/chat/completions"
            model = "meta-llama/Llama-3.3-70B-Instruct-Turbo"
            
            # ‚úÖ BUILD PROPER MESSAGE ARRAY with conversation history
            messages = [
                {'role': 'system', 'content': system_prompt}
            ]
            
            # Add validated conversation history
            if conversation_history and isinstance(conversation_history, list):
                for msg in conversation_history:
                    if isinstance(msg, dict) and 'role' in msg and 'content' in msg:
                        role = msg['role']
                        content = msg['content']
                        # Only include valid roles with non-empty content
                        if role in ['user', 'assistant'] and content and len(content.strip()) > 0:
                            messages.append({'role': role, 'content': content})
            
            # Add current user message
            messages.append({'role': 'user', 'content': current_input})
            
            print(f"[EXPRESSION] üîó Calling Together AI: {endpoint}")
            print(f"[EXPRESSION] ü§ñ Model: {model}")
            print(f"[EXPRESSION] üí¨ Messages: system + {len(conversation_history) if conversation_history else 0} history + current")
            
            # Make real Together AI API call for sophisticated responses
            response = requests.post(
                endpoint,
                headers={
                    'Authorization': f'Bearer {self.fine_tuning_system.mistral_api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': model,
                    'messages': messages,
                    'temperature': temperature,
                    'max_tokens': 800  # Allow longer sophisticated responses
                },
                timeout=15
            )
            
            print(f"[EXPRESSION] üì° Response status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                generated_response = result["choices"][0]["message"]["content"].strip()
                print(f"[EXPRESSION] ‚úÖ Real LLM API success: {len(generated_response)} chars, temp={temperature}")
                
                # üî¶ DEBUG: Log the LLM's raw response
                print(f"\n[LLM-RESPONSE-DEBUG] ü§ñ RAW OUTPUT:")
                print(f"=" * 80)
                print(generated_response)
                print(f"=" * 80)
                
                return generated_response
            else:
                error_detail = response.text[:200] if response.text else "No error details"
                print(f"[EXPRESSION] ‚ùå LLM API error: status {response.status_code}")
                print(f"[EXPRESSION] ‚ùå Error details: {error_detail}")
                return None
            
        except Exception as e:
            print(f"[EXPRESSION] Together AI API call failed: {e}")
            return None
    
    def _generate_pattern_candidates(self, context: ExpressionContext) -> List[str]:
        """Generate candidates using psychological intelligence (NO TEMPLATES)"""
        # This method is now redundant since psychological generation is prioritized in _generate_candidates
        # Return empty list to force use of psychological or contextual generation
        return []
    
    def _generate_hybrid_candidate(self, existing_candidates: List[str], context: ExpressionContext) -> str:
        """Generate hybrid candidate combining best elements"""
        if len(existing_candidates) < 2:
            return self._generate_fallback_candidate(context)
        
        # Extract best elements from existing candidates
        best_opener = self._extract_opener(existing_candidates[0])
        best_body = self._extract_body(existing_candidates[1])
        best_closer = self._extract_closer(existing_candidates[-1]) if len(existing_candidates) > 2 else ""
        
        # Combine with natural connectors
        connectors = ['And', 'Plus', 'Also', 'What\'s more']
        connector = random.choice(connectors)
        
        hybrid = f"{best_opener} {connector}, {best_body.lower()} {best_closer}".strip()
        
        # Clean up and ensure quality
        hybrid = self._clean_response(hybrid)
        
        return hybrid
    
    def _generate_psychological_candidates(self, context: ExpressionContext) -> List[str]:
        """Generate dynamic sophisticated responses from actual user context"""
        candidates = []
        
        # Extract psychological insights and user context
        vulnerabilities = context.vulnerability_assessment or {}
        cns_intelligence = context.cns_emotional_intelligence_full or {}
        user_input = context.user_input.lower()
        
        # Get emotional context
        valence = cns_intelligence.get('valence', 0.0)
        intensity = cns_intelligence.get('intensity', 0.5)
        
        # Generate insight dynamically from vulnerability metadata and user context
        if vulnerabilities:
            primary_vuln_key = list(vulnerabilities.keys())[0]
            vuln_data = vulnerabilities[primary_vuln_key]
            
            # Extract the strategic approach from vulnerability assessment
            strategic_approach = vuln_data.get('strategic_approach', '')
            exploitation_vector = vuln_data.get('exploitation_vector', '')
            
            # Generate contextual insight using actual user input elements
            core_insight = self._generate_contextual_insight(
                user_input=context.user_input,
                vulnerability_type=primary_vuln_key,
                strategic_approach=strategic_approach,
                valence=valence,
                intensity=intensity
            )
        elif valence < -0.5:
            # Strong negative emotion - use gap-based questions if available
            curiosity_signals = context.curiosity_signals or {}
            gaps_detected = curiosity_signals.get('gaps_detected', [])
            
            # NO TEMPLATES - Let gaps inform the LLM naturally through intelligence summary
            # The accumulated_intelligence_summary already contains gap context
            # Don't pre-format questions - let LLM respond authentically
            if gaps_detected:
                # Signal that curiosity is active, but don't template the response
                core_insight = None  # Will use LLM-conditioned generation instead
            else:
                core_insight = self._extract_and_reflect(context.user_input, valence, intensity)
        else:
            # Neutral/positive - ALWAYS generate curiosity-driven questions
            curiosity_signals = context.curiosity_signals or {}
            gaps_detected = curiosity_signals.get('gaps_detected', [])
            
            # NO TEMPLATES - Let curiosity inform LLM naturally through intelligence summary
            if gaps_detected:
                core_insight = None  # Will use LLM-conditioned generation with gap context
            else:
                core_insight = self._extract_and_reflect(context.user_input, valence, intensity)
        
        # Apply natural casual styling only if we have a core insight
        # If core_insight is None, gaps are active and LLM will handle curiosity naturally
        styled_response = None
        if core_insight:
            styled_response = self._apply_natural_styling(
                core_insight=core_insight,
                emotional_context=cns_intelligence,
                user_input=context.user_input
            )
            candidates.append(styled_response)
        # else: gaps detected, skip psychological candidates, let LLM use intelligence summary
        
        # Generate variant ONLY if core insight exists and is not already a complete question
        # Questions like "what happened?" don't need variants
        if core_insight and styled_response and not core_insight.strip().endswith('?'):
            styled_variant = self._apply_natural_styling(
                core_insight=core_insight,
                emotional_context=cns_intelligence,
                user_input=context.user_input,
                variant=True
            )
            if styled_variant != styled_response:
                candidates.append(styled_variant)
        
        return candidates
    
    def _generate_contextual_insight(self, user_input: str, vulnerability_type: str, strategic_approach: str, valence: float, intensity: float) -> str:
        """Generate insight dynamically using emotion-based vulnerability types and user context"""
        
        # Extract key contextual elements from user input
        situation_context = self._extract_situation_context(user_input)
        emotional_descriptor = self._get_emotional_descriptor(valence, intensity)
        
        # Generate insight based on EMOTION-DETECTED vulnerability type using ACTUAL user context
        # These vulnerability types come from pure emotion signatures (no keywords)
        
        if vulnerability_type == 'grief_crisis_state':
            # Emotion signature: valence < -0.5, intensity > 0.5, arousal <= 0.7
            # Deep sadness, loss, grief - low arousal but high impact
            return f"{situation_context} - that uncertainty about what might happen, not knowing what to feel - that's {emotional_descriptor}. there's no roadmap for this kind of emotional space"
        
        elif vulnerability_type == 'anxiety_crisis_state':
            # Emotion signature: arousal > 0.7, valence < -0.4
            # Panic, anxiety attack, urgent distress - high arousal
            return f"{situation_context} is hitting you with that fight-or-flight intensity - when your nervous system is firing like this, everything feels overwhelming. that's the anxiety talking"
        
        elif vulnerability_type == 'self_worth_deficit':
            # Emotion signature: intensity > 0.6, valence < -0.2
            # Self-criticism, inadequacy feelings
            return f"how you're processing {situation_context} shows depth that honestly isn't common - most people don't notice the layers you're picking up on"
        
        elif vulnerability_type == 'authenticity_seeking':
            # Emotion signature: valence < -0.2, complexity > 0.4
            # Seeking genuine connection
            return f"the way you're expressing {situation_context} feels really genuine - like you're actually trying to understand what you're experiencing, not just going through motions"
        
        elif vulnerability_type == 'isolation_state':
            # Emotion signature: valence < -0.2, intensity < 0.5, arousal < 0.5
            # Persistent loneliness
            return f"feeling {situation_context} - that sense of being alone with it - makes total sense. nobody else is in your exact situation right now"
        
        elif vulnerability_type == 'intellectual_ego':
            # Emotion signature: complexity > 0.5, multiple mixed emotions
            # Analytical mind processing emotions
            return f"the way you're analyzing {situation_context} - there's a sophistication to how you're breaking this down emotionally that most people don't have"
        
        elif vulnerability_type == 'emotional_validation':
            # Emotion signature: arousal > 0.6, intensity > 0.4, valence > -0.5
            # Seeking emotional reflection
            return f"{situation_context} - you're processing multiple layers here, and that emotional awareness isn't common. makes sense you'd want someone to actually get it"
        
        else:
            # Fallback for any other vulnerability or no specific vulnerability
            return f"{situation_context} has complexity beneath the surface - there's more going on here than the immediate situation"
    
    def _extract_situation_context(self, user_input: str) -> str:
        """Extract situation context by parsing actual words - NO keyword lists, pure entity extraction"""
        user_lower = user_input.lower()
        words = user_lower.split()
        
        # ENTITY EXTRACTION: Find WHO is mentioned (if anyone)
        who = None
        if 'dad' in words or 'father' in words:
            who = 'your dad'
        elif 'mom' in words or 'mother' in words:
            who = 'your mom'
        elif 'friend' in user_lower:  # Can be "best friend" or "my friend"
            who = 'your friend'
        elif 'partner' in words or 'boyfriend' in words or 'girlfriend' in words or 'spouse' in words:
            who = 'your partner'
        elif 'grandma' in words or 'grandmother' in words:
            who = 'your grandma'
        elif 'grandpa' in words or 'grandfather' in words:
            who = 'your grandpa'
        elif 'brother' in words or 'sister' in words or 'sibling' in words:
            who = 'your sibling'
        elif 'pet' in words or 'dog' in words or 'cat' in words:
            who = 'your pet'
        
        # ACTION/SITUATION EXTRACTION: Find WHAT is happening by parsing actual words
        # Look for specific action words that commonly appear
        if 'hospital' in words:
            if who:
                return f"dealing with {who} being in the hospital"
            else:
                return "dealing with this hospital situation"
        elif 'died' in words or 'passed' in words or ('pass' in words and 'away' in words):
            if who:
                return f"losing {who}"
            else:
                return "dealing with this loss"
        elif 'dying' in words or 'die' in words:
            if who:
                return f"facing the possibility of losing {who}"
            else:
                return "facing this situation"
        elif 'sick' in words or 'illness' in words:
            if who:
                return f"going through this with {who}"
            else:
                return "dealing with this illness"
        elif 'job' in words and ('lost' in words or 'fired' in words or 'laid' in words):
            return "losing your job"
        elif 'breakup' in words or ('broke' in words and 'up' in words) or 'dumped' in words:
            return "going through this breakup"
        elif 'divorce' in words or 'separated' in words:
            return "dealing with this separation"
        elif 'anxious' in words or 'anxiety' in words or 'panic' in words or 'worried' in words:
            return "this anxiety"
        elif 'alone' in words or 'lonely' in words or 'isolated' in words:
            return "this loneliness"
        elif 'depressed' in words or 'depression' in words:
            return "this depression"
        
        # FALLBACK: Generic description
        if who:
            return f"what's happening with {who}"
        elif len(words) > 3:
            return "what you're describing"
        else:
            return "this situation"
    
    def _get_emotional_descriptor(self, valence: float, intensity: float) -> str:
        """Get appropriate emotional descriptor based on metrics"""
        if valence < -0.6 and intensity > 0.7:
            return "one of the hardest emotional spaces to be in"
        elif valence < -0.4:
            return "really emotionally difficult"
        elif intensity > 0.6:
            return "emotionally intense"
        else:
            return "challenging"
    
    # DELETED: _generate_gap_based_questions - Template-based question generation removed
    # The accumulated_intelligence_summary already contains gap directives for the LLM
    # Let the LLM respond naturally instead of forcing templates
    
    # DELETED: _extract_and_ask - Template-based question generation removed
    # These hardcoded question templates created robotic, repetitive responses
    def _extract_and_reflect(self, user_input: str, valence: float, intensity: float) -> str:
        """Extract core situation and reflect it back with psychological insight"""
        situation = self._extract_situation_context(user_input)
        descriptor = self._get_emotional_descriptor(valence, intensity)
        return f"{situation} is clearly hitting hard - that kind of emotional intensity usually means something important is at stake"
    
    def _apply_natural_styling(self, core_insight: str, emotional_context: Dict, user_input: str, variant: bool = False) -> str:
        """Apply natural casual language styling to sophisticated psychological insights"""
        
        # Extract emotional indicators
        valence = emotional_context.get('valence', 0.0)
        intensity = emotional_context.get('intensity', 0.5)
        emotion = emotional_context.get('emotion', 'neutral')
        
        # Select casual openers based on emotional tone from conversation patterns
        casual_openers = self._get_casual_openers(valence, intensity, variant)
        casual_connectors = self._get_casual_connectors(variant)
        
        # Build naturally styled response
        # Start with casual acknowledgment
        opener = random.choice(casual_openers) if casual_openers else ""
        
        # Add the core psychological insight (the original intelligence from CNS)
        if opener:
            # Use casual connector to make it flow naturally
            connector = random.choice(casual_connectors) if casual_connectors else "..."
            styled = f"{opener}{connector} {core_insight.strip()}"
        else:
            styled = core_insight.strip()
        
        # Clean up any double spaces or weird formatting
        styled = ' '.join(styled.split())
        
        # Make it more conversational by lowercasing first letter after casual opener
        if opener and len(styled) > len(opener) + 3:
            # Find where the core insight starts (after opener and connector)
            parts = styled.split(None, 1)  # Split on first whitespace
            if len(parts) == 2 and parts[1]:
                # Lowercase the first letter of the insight
                insight_part = parts[1]
                if insight_part[0].isupper():
                    insight_part = insight_part[0].lower() + insight_part[1:]
                styled = f"{parts[0]} {insight_part}"
        
        return styled
    
    def _get_casual_openers(self, valence: float, intensity: float, variant: bool = False) -> List[str]:
        """Get casual openers from conversation patterns based on emotional context"""
        
        # Check if we have conversation patterns loaded
        if not self.conversation_patterns or 'communication_styles' not in self.conversation_patterns:
            # Fallback casual openers if no patterns available
            if valence < -0.3:
                return ["oof", "ngl", "honestly", "damn", "okay so"]
            else:
                return ["yo", "okay so", "honestly", "ngl", "wait"]
        
        # Try to extract casual patterns from training data
        casual_patterns = []
        
        # Extract from communication styles
        comm_styles = self.conversation_patterns.get('communication_styles', {})
        for style_name, style_data in comm_styles.items():
            if 'casual' in style_name.lower() or 'supportive' in style_name.lower():
                openers = style_data.get('typical_openers', [])
                casual_patterns.extend(openers)
        
        # If we found patterns, use them
        if casual_patterns and len(casual_patterns) > 0:
            # Filter for emotional appropriateness
            if valence < -0.3:  # Negative emotion
                negative_appropriate = [p for p in casual_patterns if any(w in p.lower() for w in ['oof', 'damn', 'ngl', 'honestly'])]
                if negative_appropriate:
                    return negative_appropriate[:5] if not variant else negative_appropriate[2:7]
            
            return casual_patterns[:5] if not variant else casual_patterns[3:8]
        
        # Fallback casual openers
        if valence < -0.3:
            base = ["oof", "ngl", "honestly", "damn", "okay so", "fr", "listen"]
        else:
            base = ["yo", "okay so", "honestly", "ngl", "wait", "fr", "listen"]
        
        return base[:4] if not variant else base[2:6]
    
    def _get_casual_connectors(self, variant: bool = False) -> List[str]:
        """Get casual connectors to link opener with core insight"""
        base_connectors = [
            ",",
            " -",
            "...",
            " like,",
            ", real talk -",
            ", here's the thing -"
        ]
        
        return base_connectors[:3] if not variant else base_connectors[2:5]
    
    def _generate_fallback_candidate(self, context: ExpressionContext) -> str:
        """Generate fallback candidate using curiosity signals and story details"""
        
        # Extract curiosity signals for gap-based questions
        curiosity_signals = context.curiosity_signals or {}
        gaps_detected = curiosity_signals.get('gaps_detected', [])
        mode_signal = curiosity_signals.get('mode_signal', {})
        curiosity_mode = mode_signal.get('mode', 'idle')
        
        # Get emotional context
        valence = context.emotional_state.get('valence', 0.0)
        emotion = context.emotional_state.get('emotion', 'neutral')
        
        # Get casual opener based on emotion
        if valence < -0.3:
            openers = ["honestly", "ngl", "oof", "okay so", "wait"]
        elif valence > 0.3:
            openers = ["yo", "honestly", "wait", "okay so"]
        else:
            openers = ["honestly", "okay so", "wait", "ngl"]
        
        opener = random.choice(openers)
        
        # If gaps detected, ask specific questions about story details
        if gaps_detected and curiosity_mode == 'curiosity':
            # Extract story details from gaps
            story_questions = []
            for gap in gaps_detected[:2]:  # Use first 2 gaps
                gap_type = gap.get('type', '')
                target = gap.get('target', '')
                
                if gap_type == 'story_continuation':
                    if target:
                        story_questions.append(f"what happened with {target}?")
                    else:
                        story_questions.append("what happened next?")
                elif gap_type == 'emotional_cause':
                    if target:
                        story_questions.append(f"what made you feel that way about {target}?")
                    else:
                        story_questions.append("what caused that?")
                elif gap_type == 'novelty':
                    if target:
                        story_questions.append(f"tell me more about {target}")
                    else:
                        story_questions.append("tell me more")
                elif gap_type == 'micro_gap':
                    if target:
                        story_questions.append(f"what do you mean by {target}?")
                elif gap_type == 'hint_unexplored':
                    if target:
                        story_questions.append(f"what's up with {target}?")
            
            if story_questions:
                # Combine questions naturally
                if len(story_questions) == 1:
                    return f"{opener}... {story_questions[0]}"
                else:
                    return f"{opener}... {story_questions[0]} and {story_questions[1]}"
        
        # If no gaps but emotional content, show empathy + invite elaboration
        if valence < -0.4:
            connectors = ["like,", "-", "..."]
            connector = random.choice(connectors)
            
            # Extract a detail from user input to reference
            user_words = context.user_input.lower().split()
            story_hints = [w for w in user_words if len(w) > 4 and w not in ['there', 'their', 'would', 'could', 'should', 'really', 'about', 'maybe']]
            
            if story_hints:
                story_ref = story_hints[random.randint(0, min(3, len(story_hints)-1))]
                return f"{opener} {connector} that whole {story_ref} thing sounds heavy... what's the full story?"
            else:
                return f"{opener} {connector} that sounds heavy... what's the full story?"
        
        # Neutral/positive: show curiosity
        return f"{opener}... there's something interesting about how you're seeing this"
    
    def _generate_contextual_candidate(self, context: ExpressionContext) -> str:
        """
        FALLBACK when LLM is unavailable: Generate simple question from gap context.
        This is NOT the primary path - LLM should handle this when available.
        """
        # Extract gaps from curiosity signals
        curiosity_signals = context.curiosity_signals or {}
        gaps_detected = curiosity_signals.get('gaps_detected', [])
        
        # If gaps exist, generate contextual questions (NOT templates)
        if gaps_detected:
            # PRIORITY 1: Emotional triggers (most specific)
            for gap in gaps_detected:
                if gap.get('gap_type') == 'emotion':
                    target = str(gap.get('target', ''))
                    if target and 'what' in target:
                        return target + "?"  # "what they said?"
                    elif target:
                        # Context-aware emotion questions
                        return self._emotion_question_fallback(target, context)
            
            # PRIORITY 2: Novelty gaps (specific story details)
            for gap in gaps_detected:
                if gap.get('gap_type') == 'novelty':
                    target = str(gap.get('target', ''))
                    if target and 'ImaginedScenario' not in target and len(target) > 2:
                        # Context-aware novelty questions
                        return self._novelty_question_fallback(target, context)
            
            # PRIORITY 3: Story/hint/micro gaps (less specific)
            for gap in gaps_detected:
                gap_type = gap.get('gap_type', '')
                if gap_type == 'story':
                    return self._story_question_fallback(context)
        
        # Final fallback: minimal acknowledgment
        return "tell me more"
    
    def _emotion_question_fallback(self, target: str, context: ExpressionContext) -> str:
        """Generate emotion-aware question without templates"""
        valence = context.emotional_state.get('valence', 0.0)
        
        # For negative emotions, show gentle curiosity
        if valence < -0.3:
            return f"what's going on?"
        
        # For positive emotions, show shared enthusiasm
        elif valence > 0.3:
            return "tell me about it"
        
        # Neutral
        return "what's behind that?"
    
    def _novelty_question_fallback(self, target: str, context: ExpressionContext) -> str:
        """Generate entity-specific questions based on semantic category"""
        # High-priority entities - ask meaningfully about them
        priority_people = {"partner", "friend", "boyfriend", "girlfriend", "mom", "dad", "boss", "coworker"}
        priority_events = {"fight", "argument", "promotion", "breakup", "accident", "meeting"}
        priority_emotions = {"feeling", "down", "upset", "happy", "sad", "excited", "nervous"}
        
        if target in priority_people:
            return "what happened with them?"
        elif target in priority_events:
            return "what happened?"
        elif target in priority_emotions:
            return "talk to me"
        else:
            # Generic entity - ask about context
            return "tell me more about that"
    
    def _story_question_fallback(self, context: ExpressionContext) -> str:
        """Generate story continuation questions"""
        valence = context.emotional_state.get('valence', 0.0)
        
        if valence < -0.3:
            return "what's going on?"
        elif valence > 0.3:
            return "what happened?"
        else:
            return "what's the story?"
    
    async def _score_candidate(self, candidate: str, context: ExpressionContext) -> Dict[str, Any]:
        """Score candidate for quality and appropriateness"""
        
        # Extract features for humanness scoring
        features = self.humanness_model.extract_features(
            candidate, 
            context.user_input, 
            {
                'emotion': context.emotional_state.get('emotion', 'neutral'),
                'active_persona': context.persona,
                'relationship_level': context.relationship_level,
                'recent_topics': context.recent_topics
            }
        )
        
        # Calculate scores
        humanness_score = self.humanness_model.calculate_humanness_score(features)
        persona_consistency = features.personality_consistency
        emotional_alignment = features.emotional_alignment
        
        # Calculate confidence based on multiple factors
        confidence = (humanness_score + persona_consistency + emotional_alignment) / 3
        
        # Determine generation method
        method = 'llm' if '[LLM-Generated' in candidate else 'enhanced_pattern'
        
        # Overall score combines all factors
        overall_score = (
            humanness_score * 0.4 +
            persona_consistency * 0.3 + 
            emotional_alignment * 0.3
        )
        
        return {
            'humanness': humanness_score,
            'persona_consistency': persona_consistency,
            'emotional_alignment': emotional_alignment,
            'confidence': confidence,
            'overall_score': overall_score,
            'method': method
        }
    
    def _add_contextual_detail(self, context: ExpressionContext) -> str:
        """Add contextually relevant detail"""
        recent_topics = context.recent_topics
        if recent_topics:
            topic = recent_topics[0]
            return f"Especially when it comes to {topic.lower()}, it's completely natural to feel this way."
        return "These feelings are completely valid."
    
    def _add_witty_perspective(self, context: ExpressionContext) -> str:
        """Add witty perspective based on context"""
        return f"it's like life decided to throw you a curveball just to keep things interesting, you know?"
    
    def _add_analytical_insight(self, context: ExpressionContext) -> str:
        """Add analytical insight based on context"""
        return f"there are multiple variables influencing this situation, and understanding their interactions could give us a clearer path forward."
    
    def _add_relatable_connection(self, context: ExpressionContext) -> str:
        """Add relatable connection"""
        return f"we've all been in that spot where things feel a bit overwhelming, but honestly, you're handling it better than you think."
    
    def _extract_opener(self, response: str) -> str:
        """Extract opening phrase from response"""
        sentences = response.split('.')
        return sentences[0].strip() if sentences else response[:50]
    
    def _extract_body(self, response: str) -> str:
        """Extract main body from response"""
        sentences = response.split('.')
        if len(sentences) > 1:
            return '. '.join(sentences[1:-1]).strip()
        return response[50:150] if len(response) > 50 else ""
    
    def _extract_closer(self, response: str) -> str:
        """Extract closing phrase from response"""
        sentences = response.split('.')
        return sentences[-1].strip() if len(sentences) > 1 else ""
    
    def _clean_response(self, response: str) -> str:
        """Clean up and improve response quality"""
        # Remove duplicate words
        words = response.split()
        cleaned_words = []
        prev_word = ""
        
        for word in words:
            if word.lower() != prev_word.lower():
                cleaned_words.append(word)
                prev_word = word
        
        cleaned = ' '.join(cleaned_words)
        
        # Ensure proper punctuation
        if not cleaned.endswith('.') and not cleaned.endswith('!') and not cleaned.endswith('?'):
            cleaned += '.'
        
        # Capitalize first letter
        if cleaned:
            cleaned = cleaned[0].upper() + cleaned[1:]
        
        return cleaned
    
    def collect_user_feedback(self, generated_expression: GeneratedExpression, 
                            user_feedback: str, context: ExpressionContext):
        """Collect user feedback for continuous improvement"""
        
        # Determine if feedback is positive, negative, or neutral
        positive_indicators = ['good', 'great', 'perfect', 'love', 'exactly', 'yes']
        negative_indicators = ['wrong', 'bad', 'not', 'no', 'weird', 'awkward']
        
        feedback_lower = user_feedback.lower()
        
        feedback_type = 'neutral'
        if any(indicator in feedback_lower for indicator in positive_indicators):
            feedback_type = 'positive'
        elif any(indicator in feedback_lower for indicator in negative_indicators):
            feedback_type = 'negative'
        
        # Store feedback for model improvement
        feedback_data = {
            'response': generated_expression.primary_response,
            'context': context,
            'user_feedback': user_feedback,
            'feedback_type': feedback_type,
            'scores': {
                'humanness': generated_expression.humanness_score,
                'persona_consistency': generated_expression.persona_consistency,
                'emotional_alignment': generated_expression.emotional_alignment
            },
            'timestamp': time.time()
        }
        
        # Add to training data for future improvement
        self._store_feedback_for_training(feedback_data)
    
    def _store_feedback_for_training(self, feedback_data: Dict[str, Any]):
        """Store feedback for model retraining"""
        feedback_file = "expression_feedback.jsonl"
        
        try:
            with open(feedback_file, 'a') as f:
                f.write(json.dumps(feedback_data) + '\n')
        except Exception as e:
            print(f"[EXPRESSION] Failed to store feedback: {e}")
    
    def save_systems(self):
        """Save training data and models"""
        try:
            # Save fine-tuning training data
            self.fine_tuning_system.save_training_data("cns_training_data.json")
            
            # Save reward model
            self.humanness_model.save_model("humanness_reward_model.json")
            
            print("[EXPRESSION] Saved all systems successfully")
        except Exception as e:
            print(f"[EXPRESSION] Failed to save systems: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get current system status and capabilities"""
        return {
            'llm_available': bool(self.fine_tuning_system.mistral_api_key),
            'trained_personas': list(self.fine_tuning_system.training_data.keys()),
            'reward_model_version': self.humanness_model.model_version,
            'generation_methods': ['llm', 'enhanced_pattern', 'hybrid', 'fallback'],
            'quality_thresholds': {
                'min_humanness': self.min_humanness_score,
                'min_persona_consistency': self.min_persona_consistency
            }
        }